{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23949,"status":"ok","timestamp":1741231293036,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"pLmZUgDwcA5r","outputId":"ee3906bb-f9d8-4cfd-b9a1-1cc668fa2ded"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/IndividualProject/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_UMWXYPcMpr"},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","import pickle as pkl\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import (precision_score, recall_score, f1_score, \n","                             accuracy_score, confusion_matrix, classification_report)\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from ST_GCN.st_gcn import Model as STGCN\n","from WO_GMA.wogma import WOGMA\n","from SkateFormer.SkateFormer import SkateFormer_ as SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UtrlnbCanQwS"},"outputs":[],"source":["def compute_effective_number_weights(labels, beta=0.9999):\n","    \"\"\"\n","    Compute class weights based on the effective number of samples.\n","\n","    Args:\n","        labels (array-like): Array or list of class labels.\n","        beta (float): Hyperparameter in [0, 1). Typically very close to 1.\n","\n","    Returns:\n","        dict: Mapping from class label to computed weight.\n","    \"\"\"\n","    classes, counts = np.unique(labels, return_counts=True)\n","    weights = {}\n","    for cls, count in zip(classes, counts):\n","        effective_num = 1.0 - beta ** count\n","        weights[cls] = (1.0 - beta) / effective_num if effective_num != 0 else 0.0\n","    # Optional: normalize weights so that their sum is 1\n","    weight_sum = sum(weights.values())\n","    weights = {cls: float(w / weight_sum) for cls, w in weights.items()}\n","    return weights\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_confuse_matrix(y_true, y_pred, classes):\n","    \"\"\"\n","    Plot confusion matrix using seaborn.\n","    \"\"\"\n","    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n","    plt.figure(figsize=(5, 4))\n","    sns.heatmap(cm, annot=True, cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n","    plt.xlabel('Predicted label')\n","    plt.ylabel('True label')\n","    plt.title('Confusion Matrix')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLlcSNE_dTCR"},"outputs":[],"source":["class SkeletalDataset(Dataset):\n","    \"\"\"\n","    A custom Dataset for 2D skeletal data.\n","\n","    Each sample corresponds to one participantâ€™s bag:\n","      - bag: Tensor of shape (num_segments, 6, 100, 5, 1)\n","      - label: Tensor of shape (7,) containing more information.\n","    \"\"\"\n","    def __init__(self, bag_data_list, labels, transform=None):\n","        \"\"\"\n","        Args:\n","            bag_data_list (list): List where each element is a bag (can be a numpy array or a torch.Tensor).\n","            labels (list): Each label is an array-like of shape (9,).\n","            transform (callable, optional): Optional transform to be applied on a bag.\n","        \"\"\"\n","        assert len(bag_data_list) == len(labels), \"Data and labels must have the same length.\"\n","        self.bag_data_list = bag_data_list\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.bag_data_list)\n","\n","    def __getitem__(self, idx):\n","        bag = self.bag_data_list[idx]\n","        # Convert bag to torch tensor if it isn't already.\n","        if not isinstance(bag, torch.Tensor):\n","            bag = torch.tensor(bag, dtype=torch.float)\n","        label = self.labels[idx]\n","        # Convert label to tensor.\n","        label = torch.tensor(label, dtype=torch.float)\n","        if self.transform:\n","            bag = self.transform(bag)\n","        return bag, label\n","\n","def collate_fn(batch):\n","    \"\"\"\n","    Custom collate function for a batch_size of 1.\n","    It takes the single sample in the batch and ensures that the label has a batch dimension.\n","    \"\"\"\n","    bag, label = batch[0]\n","    if label.dim() == 1:\n","        label = label.unsqueeze(0)\n","    return bag, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjXZmRxKdGKT"},"outputs":[],"source":["def load_pretrained_model(model_type='st_gcn', checkpoint_path=None, device='cpu'):\n","    \"\"\"\n","    Construct the ST-GCN architecture, then load your pretrained weights.\n","    \"\"\"\n","    if model_type == 'st_gcn':\n","        model = STGCN(\n","            num_class=NUM_CLASS,\n","            in_channels=IN_CHANNEL,\n","            graph_args={'strategy': 'spatial'},\n","            dropout=DROPOUT,\n","            edge_importance_weighting=True\n","        )\n","    elif model_type == 'ctr_gcn':\n","        model = CTR_GCN(\n","            graph_args={'strategy': 'spatial'}, \n","            drop_out=DROPOUT, \n","            in_channels=IN_CHANNEL, \n","            num_class=NUM_CLASS).to(device)\n","    elif model_type == 'skateformer':\n","        model = Skateformer(\n","            num_frames=64,\n","        )\n","    else:\n","        raise ValueError(f\"Invalid model type: {model_type}\")\n","            \n","    # Load checkpoint\n","    ckpt = torch.load(checkpoint_path, map_location=device)\n","    model.load_state_dict(ckpt)\n","    model.to(device)\n","    model.eval()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hELSzCpscXya"},"outputs":[],"source":["def train_mil(epoch, model, loader, device, optimizer, scheduler=None, disease='dystonia', verbose=True):\n","    \"\"\"\n","    Run one epoch of MIL training. Return (avg_loss, accuracy).\n","    \n","    label_type: 'dystonia' => label[:,3], 'choreoathetosis' => label[:,4].\n","    \"\"\"\n","    model.train()\n","    if scheduler and verbose:\n","        print(\"Learning Rate:\", scheduler.get_last_lr()[0])\n","    else:\n","        # If no scheduler was given, we can directly query the optimizer:\n","        for param_group in optimizer.param_groups:\n","            if verbose:\n","                print(\"Learning Rate:\", param_group['lr'])\n","    \n","    running_loss = 0.0\n","    total_count = 0\n","    correct = 0\n","\n","    for bag, label in loader:\n","        bag = bag.to(device)\n","        if disease == 'dystonia_duration':\n","            video_label = label[:, 3].long().item()\n","        elif disease == 'dystonia_amplitude':\n","            video_label = label[:, 4].long().item()\n","        elif disease == 'choreoathetosis_duration':\n","            video_label = label[:, 5].long().item()\n","        elif disease == 'choreoathetosis_amplitude':\n","            video_label = label[:, 6].long().item()\n","        elif disease == 'dystonia':\n","            video_label = label[:, 7].long().item()\n","        elif disease == 'choreoathetosis':\n","            video_label = label[:, 8].long().item()\n","        else:\n","            raise ValueError(\"Invalid label_type\")\n","\n","        out = model(bag, gt_label=video_label)  # returns dict with \"loss_total\" etc.\n","        loss = out[\"loss_total\"]\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        total_count += 1\n","\n","        # For accuracy, look at out[\"video_scores_oamb\"] (or whichever aggregator you prefer)\n","        scores = out[\"video_scores_oamb\"]  # shape (2,)\n","        probs = F.softmax(scores, dim=0)\n","        pred = 1 if probs[1] > 0.5 else 0\n","        if pred == video_label:\n","            correct += 1\n","\n","    if scheduler:\n","        scheduler.step()\n","\n","    avg_loss = running_loss / total_count if total_count else 0\n","    accuracy = correct / total_count if total_count else 0\n","    if verbose:\n","        print(f\"Epoch {epoch+1} => Train Loss: {avg_loss:.4f}, Train Acc: {accuracy:.4f}\")\n","    return avg_loss, accuracy\n","\n","def test_mil(epoch, model, loader, device, disease='dystonia', verbose=True):\n","    \"\"\"\n","    Run validation/test pass. Return (avg_loss, accuracy, f1, recall, precision, preds, labels).\n","    \"\"\"\n","    model.eval()\n","    running_loss = 0.0\n","    total_count = 0\n","    correct = 0\n","\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for bag, label in loader:\n","            bag = bag.to(device)\n","            if disease == 'dystonia_duration':\n","                video_label = label[:, 3].long().item()\n","            elif disease == 'dystonia_amplitude':\n","                video_label = label[:, 4].long().item()\n","            elif disease == 'choreoathetosis_duration':\n","                video_label = label[:, 5].long().item()\n","            elif disease == 'choreoathetosis_amplitude':\n","                video_label = label[:, 6].long().item()\n","            elif disease == 'dystonia':\n","                video_label = label[:, 7].long().item()\n","            elif disease == 'choreoathetosis':\n","                video_label = label[:, 8].long().item()\n","            else:\n","                raise ValueError(\"Invalid label_type\")\n","\n","            out = model(bag, gt_label=video_label)\n","            loss = out[\"loss_total\"]\n","            running_loss += loss.item()\n","            total_count += 1\n","\n","            scores = out[\"video_scores_oamb\"]  # shape (2,)\n","            probs = F.softmax(scores, dim=0)\n","            pred = 1 if probs[1] > 0.5 else 0\n","\n","            all_preds.append(pred)\n","            all_labels.append(video_label)\n","            if pred == video_label:\n","                correct += 1\n","\n","    avg_loss = running_loss / total_count if total_count else 0\n","    accuracy = correct / total_count if total_count else 0\n","\n","    # Additional metrics\n","    precision = precision_score(all_labels, all_preds, average='macro', zero_division=True)\n","    recall    = recall_score(all_labels, all_preds, average='macro', zero_division=True)\n","    f1        = f1_score(all_labels, all_preds, average='macro', zero_division=True)\n","    if verbose:\n","        print(f\"Epoch {epoch+1} => Val Loss: {avg_loss:.4f}, Val Acc: {accuracy:.4f}, F1: {f1:.4f}\")\n","    return avg_loss, accuracy, f1, recall, precision, all_preds, all_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M3KkiCAfcwE4"},"outputs":[],"source":["def main_mil(fold, subject_id, train_loader, val_loader, pretrained_model_path, model_type='st_gcn', disease='dystonia', verbose=True):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # 1) Load ST-GCN\n","    pretrained = load_pretrained_model(model_type=model_type, pretrained_model_path=pretrained_model_path, device=device)\n","    # Freeze ST-GCN\n","    for param in pretrained.parameters():\n","        param.requires_grad = False\n","\n","    # 2) Compute class weights for MIL\n","    #    Assume we use the same approach as your ST-GCN code\n","    train_labels = np.array(train_loader.dataset.labels)\n","    if disease == 'dystonia_duration':\n","        ld = train_labels[:, 3]\n","    elif disease == 'dystonia_amplitude':\n","        ld = train_labels[:, 4]\n","    elif disease == 'choreoathetosis_duration':\n","        ld = train_labels[:, 5]\n","    elif disease == 'choreoathetosis_amplitude':\n","        ld = train_labels[:, 6]\n","    elif disease == 'dystonia':\n","        ld = train_labels[:, 7]\n","    elif disease == 'choreoathetosis':\n","        ld = train_labels[:, 8]\n","        raise ValueError(f\"Invalid disease type {disease}\")\n","    \n","    weights_dict = compute_effective_number_weights(ld)\n","    # Typically, class 0 => weights_dict[0], class 1 => weights_dict[1]\n","    weight_vec = [weights_dict.get(0, 1.0), weights_dict.get(1, 1.0)]\n","    print(\"Class weights:\", weight_vec)\n","\n","    # 3) Build WOGMA\n","    model = WOGMA(\n","        pretrained_model=pretrained,\n","        feature_dim=32,\n","        hidden_dim=128,\n","        num_classes=2,\n","        top_k_ratio=8,\n","        theta_class=0.4,\n","        theta_score=0.3,\n","        class_weights=weight_vec\n","    ).to(device)\n","\n","    optimizer = optim.Adam(\n","        filter(lambda p: p.requires_grad, model.parameters()),\n","        lr=1e-4,\n","        weight_decay=1e-4\n","    )\n","\n","    # 4) Train loop\n","    num_epochs = 100\n","    best_score = -1\n","    best_model_weights = None\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-7)\n","\n","    train_losses, val_losses = [], []\n","    train_accs, val_accs = [], []\n","    val_f1s = []\n","\n","    for epoch in range(num_epochs):\n","        # ---- Train ----\n","        tr_loss, tr_acc = train_mil(\n","            epoch, model, train_loader, device, optimizer, scheduler, disease=disease, verbose=verbose\n","        )\n","        train_losses.append(tr_loss)\n","        train_accs.append(tr_acc)\n","\n","        # ---- Validate ----\n","        val_loss, val_acc, f1, recall, precision, preds, labels = test_mil(\n","            epoch, model, val_loader, device, disease=disease, verbose=verbose\n","        )\n","        val_losses.append(val_loss)\n","        val_accs.append(val_acc)\n","        val_f1s.append(f1)\n","\n","        # Weighted metric for best model\n","        # e.g., 0.6 * f1 + 0.4 * val_acc\n","        val_metric = 0.6 * f1 + 0.4 * val_acc\n","        if val_metric > best_score:\n","            best_score = val_metric\n","            best_model_weights = model.state_dict().copy()\n","\n","    # 5) Save best model\n","    out_dir = f\"./Data/6-leave_one_out/subject{subject_id}/fold_{fold}/{disease}/{model_type}/mil\"\n","    os.makedirs(out_dir, exist_ok=True)\n","    best_model_path = os.path.join(out_dir, \"best_mil_model.pth\")\n","\n","    if best_model_weights is not None:\n","        torch.save(best_model_weights, best_model_path)\n","        print(f\"[INFO] Best MIL model saved => {best_model_path}\")\n","\n","    # Plot training curves (optional)\n","    plt.figure()\n","    plt.plot(train_losses, label='Train Loss')\n","    plt.plot(val_losses, label='Val Loss')\n","    plt.title(f\"Subject {subject_id} - Fold {fold} MIL Training Loss\")\n","    plt.legend()\n","    plt.show()\n","\n","    plt.figure()\n","    plt.plot(train_accs, label='Train Acc')\n","    plt.plot(val_accs, label='Val Acc')\n","    plt.title(f\"Subject {subject_id} - Fold {fold} MIL Accuracy\")\n","    plt.legend()\n","    plt.show()\n","\n","    return best_model_path, weight_vec"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def inference_mil(best_mil_model_path, stgcn_checkpoint_path, test_loader, device, weight_vec, model_type='st_gcn', disease='dystonia'):\n","    \"\"\"\n","    Load best model + pretrained ST-GCN, run inference on test_loader.\n","    Returns (all_preds, all_labels).\n","    \"\"\"\n","    # 1) Load ST-GCN\n","    stgcn_pretrained = load_pretrained_model(model_type, stgcn_checkpoint_path, device=device)\n","    for param in stgcn_pretrained.parameters():\n","        param.requires_grad = False\n","\n","    # 2) We'll assume you stored the class weights somewhere or you can pass [1,1] if unknown\n","    #    Or if you want, read from file. For simplicity, let's do uniform here:\n","\n","    model = WOGMA(\n","        stgcn_pretrained_model=stgcn_pretrained,\n","        feature_dim=32,\n","        hidden_dim=128,\n","        num_classes=2,\n","        top_k_ratio=8,\n","        theta_class=0.4,\n","        theta_score=0.3,\n","        class_weights=weight_vec\n","    ).to(device)\n","\n","    # Load best weights\n","    ckpt = torch.load(best_mil_model_path, map_location=device)\n","    model.load_state_dict(ckpt)\n","    model.eval()\n","\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for bag, label in test_loader:\n","            bag = bag.to(device)\n","            if disease == 'dystonia_duration':\n","                video_label = label[:, 3].long().item()\n","            elif disease == 'dystonia_amplitude':\n","                video_label = label[:, 4].long().item()\n","            elif disease == 'choreoathetosis_duration':\n","                video_label = label[:, 5].long().item()\n","            elif disease == 'choreoathetosis_amplitude':\n","                video_label = label[:, 6].long().item()\n","            elif disease == 'dystonia':\n","                video_label = label[:, 7].long().item()\n","            elif disease == 'choreoathetosis':\n","                video_label = label[:, 8].long().item()\n","            else:\n","                raise ValueError(\"Invalid label_type\")\n","\n","            out = model(bag, gt_label=video_label)\n","            scores = out[\"video_scores_oamb\"]\n","            probs = F.softmax(scores, dim=0)\n","            pred = 1 if probs[1] > 0.5 else 0\n","\n","            all_preds.append(pred)\n","            all_labels.append(video_label)\n","\n","    return np.array(all_preds), np.array(all_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1441459,"status":"ok","timestamp":1741122020186,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"pxQbhNi0cYYB","outputId":"7a86bdf0-b535-477e-8288-8ec5f3c0ba20"},"outputs":[],"source":["def run_loso_5_fold_training_mil(disease='dystonia', model_type='st_gcn', verbose=True):\n","    \"\"\"\n","    Example structure that parallels ST-GCN's LOSO + 5-fold approach.\n","    Adjust file paths to match your directory layout.\n","    \n","    Data structure assumption:\n","      ./Data/6-leave_one_out/subjectX/\n","          test_data.npy\n","          test_labels.pkl\n","          fold_0/\n","             train_data.npy\n","             train_labels.pkl\n","             val_data.npy\n","             val_labels.pkl\n","             ...\n","    \"\"\"\n","    base_loso_dir = \"./Data/6-leave_one_out\"\n","    subject_dirs = sorted(glob.glob(os.path.join(base_loso_dir, \"subject*\")))\n","\n","    all_preds_global = []\n","    all_labels_global = []\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    \n","    for subj_path in subject_dirs:\n","\n","        subject_id = os.path.basename(subj_path).replace(\"subject\", \"\")\n","        print(f\"\\n====== LOSO for subject {subject_id} ======\")\n","\n","        pretrained_checkpoint_path = f\"./Data/6-leave_one_out/subject{subject_id}/{disease}/{model_type}/best_model.pth\"\n","\n","        # 1) Test data\n","        test_data_path = os.path.join(subj_path, \"test_data.npy\")\n","        test_label_path = os.path.join(subj_path, \"test_labels.pkl\")\n","        if not (os.path.exists(test_data_path) and os.path.exists(test_label_path)):\n","            print(f\"[WARN] Missing test data for subject {subject_id}. Skipping.\")\n","            continue\n","\n","        best_fold = None\n","        best_fold_score = -999\n","        best_fold_model_path = None\n","        best_fold_model = None\n","        best_fold_class_weights = None\n","\n","        # 2) For each fold_0..4\n","        for fold_num in range(5):\n","            fold_dir = os.path.join(subj_path, f\"fold_{fold_num}\")\n","            if not os.path.isdir(fold_dir):\n","                print(f\"[WARN] No fold_{fold_num} directory. Skipping.\")\n","                continue\n","\n","            # -- train/val data\n","            train_data_path = os.path.join(fold_dir, \"train_data.npy\")\n","            train_label_path = os.path.join(fold_dir, \"train_labels.pkl\")\n","            val_data_path   = os.path.join(fold_dir, \"val_data.npy\")\n","            val_label_path  = os.path.join(fold_dir, \"val_labels.pkl\")\n","\n","            if not all(os.path.exists(p) for p in [train_data_path, train_label_path, val_data_path, val_label_path]):\n","                print(f\"[WARN] Missing train/val for fold_{fold_num}. Skipping.\")\n","                continue\n","\n","            # --- Build MIL Datasets ---\n","            # Convert your data into \"bags\" if needed. \n","            # If you already have them in the shape (num_samples, 6, T, V, 1), \n","            # you may just do something simpler. \n","            # Below is an example showing how you'd group data per ID to create bags.\n","            \n","            # Load raw arrays\n","            train_data_raw = np.load(train_data_path)  # shape depends on your saving format\n","            train_labels_raw = pkl.load(open(train_label_path, 'rb'))\n","            val_data_raw   = np.load(val_data_path)\n","            val_labels_raw = pkl.load(open(val_label_path, 'rb'))\n","\n","            # Example splitting (for L/R). Adjust if needed.\n","            LEFT, RIGHT = 12, 11\n","            # Split\n","            left_indices_train  = np.where(train_labels_raw[:,1] == LEFT)\n","            right_indices_train = np.where(train_labels_raw[:,1] == RIGHT)\n","            left_data_train  = train_data_raw[left_indices_train]\n","            right_data_train = train_data_raw[right_indices_train]\n","            left_labels_train  = train_labels_raw[left_indices_train]\n","            right_labels_train = train_labels_raw[right_indices_train]\n","\n","            # Make bag_data_list, labels\n","            # For each unique ID, gather all left segments => 1 bag, all right segments => 1 bag\n","            train_bag_list = []\n","            train_bag_labels = []\n","            ids_train = np.unique(train_labels_raw[:,0])\n","            for pid in ids_train:\n","                # left\n","                bag_left_data  = left_data_train[np.where(left_labels_train[:,0] == pid)]\n","                bag_left_label = left_labels_train[np.where(left_labels_train[:,0] == pid)]\n","                if len(bag_left_label) > 0:\n","                    train_bag_list.append(bag_left_data)\n","                    train_bag_labels.append(bag_left_label[0])\n","\n","                # right\n","                bag_right_data  = right_data_train[np.where(right_labels_train[:,0] == pid)]\n","                bag_right_label = right_labels_train[np.where(right_labels_train[:,0] == pid)]\n","                if len(bag_right_label) > 0:\n","                    train_bag_list.append(bag_right_data)\n","                    train_bag_labels.append(bag_right_label[0])\n","\n","            # Build dataset\n","            train_dataset = SkeletalDataset(train_bag_list, train_bag_labels)\n","            train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n","\n","            # --- same for val ---\n","            left_indices_val  = np.where(val_labels_raw[:,1] == LEFT)\n","            right_indices_val = np.where(val_labels_raw[:,1] == RIGHT)\n","            left_data_val  = val_data_raw[left_indices_val]\n","            right_data_val = val_data_raw[right_indices_val]\n","            left_labels_val  = val_labels_raw[left_indices_val]\n","            right_labels_val = val_labels_raw[right_indices_val]\n","\n","            val_bag_list = []\n","            val_bag_labels = []\n","            ids_val = np.unique(val_labels_raw[:,0])\n","            for pid in ids_val:\n","                bag_left_data  = left_data_val[np.where(left_labels_val[:,0] == pid)]\n","                bag_left_label = left_labels_val[np.where(left_labels_val[:,0] == pid)]\n","                if len(bag_left_label) > 0:\n","                    val_bag_list.append(bag_left_data)\n","                    val_bag_labels.append(bag_left_label[0])\n","\n","                bag_right_data  = right_data_val[np.where(right_labels_val[:,0] == pid)]\n","                bag_right_label = right_labels_val[np.where(right_labels_val[:,0] == pid)]\n","                if len(bag_right_label) > 0:\n","                    val_bag_list.append(bag_right_data)\n","                    val_bag_labels.append(bag_right_label[0])\n","\n","            val_dataset = SkeletalDataset(val_bag_list, val_bag_labels)\n","            val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n","\n","            # --- Train & Evaluate model on this fold ---\n","            best_mil_model_path, class_weights = main_mil(\n","                fold=fold_num,\n","                subject_id=subject_id,\n","                train_loader=train_loader,\n","                val_loader=val_loader,\n","                stgcn_checkpoint_path=pretrained_checkpoint_path,\n","                model_type=model_type,\n","                disease=disease,\n","                verbose=verbose\n","            )\n","\n","            # Evaluate on the validation set to pick the best fold\n","            model_temp = WOGMA(\n","                stgcn_pretrained_model=load_pretrained_model(model_type=model_type, pretrained_checkpoint_path=pretrained_checkpoint_path, device=device),\n","                feature_dim=32,\n","                hidden_dim=128,\n","                num_classes=2,\n","                top_k_ratio=8,\n","                theta_class=0.4,\n","                theta_score=0.3,\n","                class_weights=class_weights\n","            ).to(device)\n","\n","            model_temp.load_state_dict(torch.load(best_mil_model_path, map_location=device))\n","            model_temp.eval()\n","\n","            # Quick validation pass\n","            _, val_acc_temp, f1_temp, _, _, preds_temp, labels_temp = test_mil(\n","                epoch=999, \n","                model=model_temp, \n","                loader=val_loader, \n","                device=device, \n","                label_type=disease,\n","                verbose=verbose\n","            )\n","            fold_metric = 0.6 * f1_temp + 0.4 * val_acc_temp\n","            if fold_metric > best_fold_score:\n","                best_fold_score = fold_metric\n","                best_fold = fold_num\n","                best_fold_model_path = best_mil_model_path\n","                best_fold_model = model_temp\n","                best_fold_class_weights = class_weights\n","\n","        # Once we've found the best fold, do test inference\n","        if best_fold_model_path is None:\n","            print(f\"[WARN] No valid folds for subject {subject_id}. Skipping test inference.\")\n","            continue\n","\n","        troch.save(best_fold_model.state_dict(), f\"./Data/6-leave_one_out/subject{subject_id}/{disease}/{model_type}/mil_best_model.pth\")\n","        print(f\"[Subject {subject_id}] Best fold {best_fold} => metric = {best_fold_score:.4f}\")\n","        \n","        # 3) Test inference\n","        test_data = np.load(test_data_path)\n","        test_labels = pkl.load(open(test_label_path, 'rb'))\n","\n","        # Build test 'bags' similarly to how we built train/val\n","        left_indices_test  = np.where(test_labels[:,1] == 12)\n","        right_indices_test = np.where(test_labels[:,1] == 11)\n","\n","        left_data_test  = test_data[left_indices_test]\n","        right_data_test = test_data[right_indices_test]\n","        left_labels_test  = test_labels[left_indices_test]\n","        right_labels_test = test_labels[right_indices_test]\n","\n","        test_bag_list = []\n","        test_bag_labels = []\n","        ids_test = np.unique(test_labels[:,0])\n","        for pid in ids_test:\n","            bag_left_data  = left_data_test[np.where(left_labels_test[:,0] == pid)]\n","            bag_left_label = left_labels_test[np.where(left_labels_test[:,0] == pid)]\n","            if len(bag_left_label) > 0:\n","                test_bag_list.append(bag_left_data)\n","                test_bag_labels.append(bag_left_label[0])\n","\n","            bag_right_data  = right_data_test[np.where(right_labels_test[:,0] == pid)]\n","            bag_right_label = right_labels_test[np.where(right_labels_test[:,0] == pid)]\n","            if len(bag_right_label) > 0:\n","                test_bag_list.append(bag_right_data)\n","                test_bag_labels.append(bag_right_label[0])\n","\n","        test_dataset = SkeletalDataset(test_bag_list, test_bag_labels)\n","        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n","\n","        preds_subj, labels_subj = inference_mil(\n","            best_mil_model_path=best_fold_model_path,\n","            stgcn_checkpoint_path=pretrained_checkpoint_path,\n","            test_loader=test_loader,\n","            device=device,\n","            model_type=model_type,\n","            disease=disease,\n","            weight_vec=best_fold_class_weights\n","        )\n","\n","        all_preds_global.append(preds_subj)\n","        all_labels_global.append(labels_subj)\n","\n","    # Global results\n","    if len(all_preds_global) == 0:\n","        print(\"\\nNo predictions collected. Check your data/folder structure.\")\n","        return\n","\n","    all_preds_global = np.concatenate(all_preds_global, axis=0)\n","    all_labels_global = np.concatenate(all_labels_global, axis=0)\n","    \n","    print(\"\\n=========== Global MIL LOSO Test Results ===========\")\n","    if disease == 'dystonia' or disease == 'choreoathetosis':\n","        classes = [0, 1]\n","    else:\n","        classes = [0, 1, 2, 3, 4]\n","\n","    plot_confuse_matrix(all_labels_global, all_preds_global, classes=classes)\n","    print(\"\\nClassification Report:\\n\", classification_report(all_labels_global, all_preds_global))\n","    print(\"Done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":619},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1741122020339,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"lMwSVF5AcuqJ","outputId":"a3237163-57e0-4cec-8a50-a7256141a80a"},"outputs":[],"source":["# plot confuse matrix\n","import seaborn as sns\n","\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(over_all_cm, annot=True, fmt='d')\n","plt.xlabel('Predicted')\n","plt.ylabel('Truth')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZPuDZv2O-cgI"},"source":["# Choreoathetosis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zy1CIk0pxoiT"},"outputs":[],"source":["def train_one_epoch(model, train_loader, device, optimizer, scheduler):\n","    \"\"\"\n","    Train WO-GMA model for one epoch.\n","    Returns average loss and classification accuracy across the training set.\n","    \"\"\"\n","    model.train()  # set to train mode\n","    running_loss = 0.0\n","    total_count = 0  # how many videos\n","    correct = 0      # how many correct\n","\n","    for bag, label in train_loader:\n","        # bag.shape:   (L, C, T, V, M)   L=clip_num\n","        # label.shape: (1, 7)           pick label[:,3] => 0 or 1\n","        bag = bag.to(device)\n","        video_label = label[:, -1].long().item()  # integer 0 or 1\n","\n","        # Forward pass\n","        out = model(bag, gt_label=video_label)  # returns dict\n","        loss = out[\"loss_total\"]                # combined MIL loss\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        #scheduler.step()\n","\n","        running_loss += loss.item()\n","        total_count += 1\n","\n","        # For training accuracy, use the OAMB aggregator\n","        #   (or CPGB aggregator, whichever you prefer for final classification).\n","        with torch.no_grad():\n","            scores = out[\"video_scores_oamb\"]  # shape (num_classes,) => (2,)\n","            # Convert to probability\n","            probs = F.softmax(scores, dim=0)   # e.g. [p_neg, p_pos]\n","            pred = 1 if probs[1] > 0.5 else 0\n","            if pred == video_label:\n","                correct += 1\n","\n","    avg_loss = running_loss / total_count if total_count else 0\n","    accuracy = correct / total_count if total_count else 0\n","\n","    return avg_loss, accuracy\n","\n","\n","def validate_one_epoch(model, val_loader, device):\n","    \"\"\"\n","    Validate WO-GMA model for one epoch.\n","    Returns average loss, classification accuracy, and also all predictions/labels\n","    for further metrics if you want (F1, confusion matrix, etc.).\n","    \"\"\"\n","    model.eval()  # set to eval mode\n","    running_loss = 0.0\n","    total_count = 0\n","    correct = 0\n","\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for bag, label in val_loader:\n","            bag = bag.to(device)\n","            video_label = label[:, -1].long().item()\n","\n","            # If you want a validation loss consistent with training,\n","            # provide gt_label here:\n","            out = model(bag, gt_label=video_label)\n","            loss = out[\"loss_total\"]\n","\n","            running_loss += loss.item()\n","            total_count += 1\n","\n","            # Classification:\n","            scores = out[\"video_scores_oamb\"]  # shape (2,)\n","            probs = F.softmax(scores, dim=0)\n","            pred = 1 if probs[1] > 0.5 else 0\n","\n","            all_preds.append(pred)\n","            all_labels.append(video_label)\n","            if pred == video_label:\n","                correct += 1\n","\n","    avg_loss = running_loss / total_count if total_count else 0\n","    accuracy = correct / total_count if total_count else 0\n","\n","    return avg_loss, accuracy, all_preds, all_labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9GT-PeK-k7D"},"outputs":[],"source":["def main(fold, mil_train_loader, mil_val_loader, disease='dystonia', model_type='st_gcn', checkpoint_path = './Data/9-kfold/3/best_model.pth'):\n","    # ----------------------------------------------------\n","    # 1) Setup your environment, device, data loaders\n","    # ----------------------------------------------------\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    stgcn_pretrained = load_pretrained_model(model_type=model, checkpoint_path=checkpoint_path, device=device)\n","\n","    # Suppose you have:\n","    # train_loader, val_loader => Dataloaders that yield (bag, label)\n","    # stgcn_pretrained => your pretrained ST-GCN (frozen or not)\n","\n","    stgcn_pretrained.eval()  # freeze if desired\n","    for param in stgcn_pretrained.parameters():\n","        param.requires_grad = False\n","\n","    train_losses, train_accs = [], []\n","    val_losses, val_accs = [], []\n","    best_preds = []\n","\n","    # Compute class weights for MIL\n","    if disease == 'dystonia_duration':\n","        ld = np.array(mil_train_loader.dataset.labels)[:, 3]\n","    elif disease == 'dystonia_amplitude':\n","        ld = np.array(mil_train_loader.dataset.labels)[:, 4]\n","    elif disease == 'choreoathetosis_duration':\n","        ld = np.array(mil_train_loader.dataset.labels)[:, 5]\n","    elif disease == 'choreoathetosis_amplitude':\n","        ld = np.array(mil_train_loader.dataset.labels)[:, 6]\n","    elif disease == 'dystonia':\n","        ld = np.array(mil_train_loader.dataset.labels)[:, 7]\n","    elif disease == 'choreoathetosis':\n","        ld = np.array(mil_train_loader.dataset.labels)[:, 8]\n","    else:\n","        raise ValueError(f\"Invalid disease type: {disease}\")\n","    \n","\n","    weights = compute_effective_number_weights(ld)\n","    print(weights)\n","    weight_vec = list(weights.values())[::-1]\n","\n","\n","    # Initialize the WOGMA model\n","    model = WOGMA(\n","        stgcn_pretrained_model=stgcn_pretrained,\n","        feature_dim=32,     # must match ST-GCN extract_feature dimension\n","        hidden_dim=128,\n","        num_classes=NUM_CLASSES,      # F+ or F-\n","        top_k_ratio=8,\n","        theta_class=0.4,\n","        theta_score=0.3,\n","        class_weights=weight_vec\n","    ).to(device)\n","\n","    # ----------------------------------------------------\n","    # 2) Set your optimizer\n","    # ----------------------------------------------------\n","    optimizer = optim.Adam(\n","        [p for p in model.parameters() if p.requires_grad],\n","        lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n","    )\n","\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n","\n","    # ----------------------------------------------------\n","    # 3) Training loop\n","    # ----------------------------------------------------\n","    num_epochs = 100\n","    best_val_f1 = 0.0\n","    best_mil_model = None\n","\n","    val_accs, val_losses = [], []\n","    train_accs, train_losses = [], []\n","    val_f1, val_recall, val_precision = [], [], []\n","    best_preds, best_labels = [], []\n","\n","    for epoch in range(num_epochs):\n","        train_loss, train_acc = train_one_epoch(model, mil_train_loader, device, optimizer, scheduler)\n","        val_loss, val_acc, preds, labels = validate_one_epoch(model, mil_val_loader, device)\n","\n","        train_losses.append(train_loss)\n","        train_accs.append(train_acc)\n","        val_losses.append(val_loss)\n","        val_accs.append(val_acc)\n","\n","        # Metrics\n","        precision = precision_score(labels, preds, average='macro', zero_division=True)\n","        recall = recall_score(labels, preds, average='macro', zero_division=True)\n","        f1 = f1_score(labels, preds, average='macro', zero_division=True)\n","        acc = accuracy_score(labels, preds)\n","\n","        val_f1.append(f1)\n","        val_recall.append(recall)\n","        val_precision.append(precision)\n","\n","        if f1 >= best_val_f1:\n","            best_val_f1 = val_f1\n","            best_preds = preds\n","            best_labels = labels\n","            best_mil_model = model\n","\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n","              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n","              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n","\n","    print(\"Done training!\")\n","\n","    torch.save(best_mil_model.state_dict(), f'./Data/9-kfold/{fold}/mil_best_model.pth')\n","\n","    val_metrics = {\n","        'val_loss': val_losses,\n","        'val_acc': val_accs,\n","        'val_f1': val_f1,\n","        'val_recall': val_recall,\n","        'val_precision': val_precision}\n","\n","    return best_mil_model, train_losses, train_accs, val_metrics, best_preds, best_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1409967,"status":"ok","timestamp":1741233550556,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"C2JbCq1--v9l","outputId":"a378bafa-a0c5-4bbe-9eea-c6ffed782796"},"outputs":[],"source":["predictions, ground_true = [], []\n","\n","for i in range(0, 6):\n","    checkpoint_path = f'./Data/9-kfold/{i}/choreoathetosis_best_model.pth'\n","    TRAIN_PARH = f'Data/9-kfold/{i}/train_data.npy'\n","    VAL_PARH = f'Data/9-kfold/{i}/validate_data.npy'\n","    TRAIN_LABEL_PATH = f'Data/9-kfold/{i}/train_binary_labels.pkl'\n","    VAL_LABEL_PATH = f'Data/9-kfold/{i}/validate_binary_labels.pkl'\n","    TEST_PARH = f'Data/9-kfold/{i}/test_data.npy'\n","    TEST_LABEL_PATH = f'Data/9-kfold/{i}/test_binary_labels.pkl'\n","    a1 = np.load(VAL_PARH)\n","    b1 = pkl.load(open(VAL_LABEL_PATH, 'rb'))\n","\n","    LEFT = 12\n","    RIGHT = 11\n","\n","    left_indices1 = np.where(b1[:, 1] == LEFT)\n","    right_indices1 = np.where(b1[:, 1] == RIGHT)\n","\n","    left_data1 = a1[left_indices1]\n","    right_data1 = a1[right_indices1]\n","\n","    left_labels1 = b1[left_indices1]\n","    right_labels1 = b1[right_indices1]\n","\n","    ids1, _ = np.unique(b1[:, 0], return_counts=True)\n","\n","    # Example usage:\n","\n","\n","    bag_data_list1 = []\n","    labels1 = []\n","\n","    for id in ids1:\n","        id_left_data1 = left_data1[np.where(left_labels1[:, 0] == id)]\n","        id_right_data1 = right_data1[np.where(right_labels1[:, 0] == id)]\n","\n","        id_left_labels1 = left_labels1[np.where(left_labels1[:, 0] == id)]\n","        id_right_labels1 = right_labels1[np.where(right_labels1[:, 0] == id)]\n","\n","        if id_left_labels1.shape[0] !=0:\n","            labels1.append(id_left_labels1[0])\n","            bag_data_list1.append(id_left_data1)\n","\n","\n","        if id_right_labels1.shape[0] !=0:\n","            labels1.append(id_right_labels1[0])\n","            bag_data_list1.append(id_right_data1)\n","\n","\n","    val_dataset = SkeletalDataset(bag_data_list1, labels1)\n","    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n","\n","    a = np.load(TRAIN_PARH)\n","    b = pkl.load(open(TRAIN_LABEL_PATH, 'rb'))\n","\n","    left_indices = np.where(b[:, 1] == LEFT)\n","    right_indices = np.where(b[:, 1] == RIGHT)\n","\n","    left_data = a[left_indices]\n","    right_data = a[right_indices]\n","\n","    left_labels = b[left_indices]\n","    right_labels = b[right_indices]\n","\n","    ids, _ = np.unique(b[:, 0], return_counts=True)\n","\n","    # Example usage:\n","\n","\n","    bag_data_list = []\n","    labels = []\n","\n","    for id in ids:\n","        id_left_data = left_data[np.where(left_labels[:, 0] == id)]\n","        id_right_data = right_data[np.where(right_labels[:, 0] == id)]\n","\n","        id_left_labels = left_labels[np.where(left_labels[:, 0] == id)]\n","        id_right_labels = right_labels[np.where(right_labels[:, 0] == id)]\n","\n","        if id_left_labels.shape[0] !=0:\n","            labels.append(id_left_labels[0])\n","            bag_data_list.append(id_left_data)\n","\n","\n","        if id_right_labels.shape[0] !=0:\n","            labels.append(id_right_labels[0])\n","            bag_data_list.append(id_right_data)\n","\n","\n","    train_dataset = SkeletalDataset(bag_data_list, labels)\n","    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n","\n","    print(f\"Fold {i}\")\n","\n","\n","    model, train_losses, train_accs, val_metrics, best_predictions, val_labels= main(fold=i, mil_train_loader=train_loader, mil_val_loader=val_loader, checkpoint_path=checkpoint_path)\n","\n","    print(len(best_predictions))\n","\n","\n","    # plot losses and metrices\n","    # Plotting the loss\n","    plt.plot(train_losses, label='Train Loss')\n","    plt.plot(val_metrics['val_loss'], label='Validation Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Plotting the metrics by using subplot\n","    fig, axs = plt.subplots(2, 2)\n","    axs[0, 0].plot(val_metrics['val_precision'], label='Precision')\n","    axs[0, 0].legend()\n","    axs[0, 1].plot(val_metrics['val_recall'], label='Recall')\n","    axs[0, 1].legend()\n","    axs[1, 0].plot(val_metrics['val_f1'], label='F1 Score')\n","    axs[1, 0].legend()\n","    axs[1, 1].plot(val_metrics['val_acc'], label='Val Accuracy')\n","    axs[1, 1].plot(train_accs, label='Train Accuracy')\n","    axs[1, 1].legend()\n","    plt.show()\n","\n","    # Plot confuse metrix for best prediction\n","    cm = confusion_matrix(val_labels, best_predictions)\n","    print(cm)\n","    print(classification_report(val_labels, best_predictions))\n","\n","    predictions.extend(best_predictions)\n","    ground_true.extend(val_labels)\n","\n","over_all_cm = confusion_matrix(ground_true, predictions)\n","print(over_all_cm)\n","plot_confuse_matrix(ground_true, predictions) \n","print(classification_report(ground_true, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["# Dystonia Duration"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='dystonia_duration', model_type='st_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='dystonia_duration', model_type='ctr_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='dystonia_duration', model_type='skateformer', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Dystonia Amplitude"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='dystonia_amplitude', model_type='st_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='dystonia_amplitude', model_type='ctr_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='dystonia_amplitude', model_type='skateformer', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Choreoathetosis Duration"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='choreoathetosis_duration', model_type='st_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='choreoathetosis_duration', model_type='ctr_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='choreoathetosis_duration', model_type='skateformer', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Choreoathetosis Amplitude"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='choreoathetosis_amplitude', model_type='st_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='choreoathetosis_amplitude', model_type='ctr_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 5\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='choreoathetosis_amplitude', model_type='skateformer', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Dystonia"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 2\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='dystonia', model_type='st_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 2\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='dystonia', model_type='ctr_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 2\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='dystonia', model_type='skateformer', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Choreoathetosis"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 2\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='choreoathetosis', model_type='st_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 2\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='choreoathetosis', model_type='ctr_gcn', verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    NUM_CLASSES = 2\n","    LEARNING_RATE = 1e-4\n","    WEIGHT_DECAY = 1e-4\n","    run_loso_5_fold_training_mil(disease='choreoathetosis', model_type='skateformer', verbose=False)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO+LyngLF4A1YMBs4K+MN7A","gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
