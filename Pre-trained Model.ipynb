{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2229,"status":"ok","timestamp":1741226349432,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"QqXBMh2qIgd3","outputId":"bbfd3f8a-a6ac-4b09-e42c-0b6e497faa32"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/IndividualProject/"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":19364,"status":"ok","timestamp":1741226369681,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"73HrYgm3LXsT"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"]}],"source":["from datetime import datetime\n","\n","import os\n","import glob\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","\n","# Place all your code inside this block\n","import torch\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import numpy as np\n","from sklearn.metrics import recall_score, f1_score, precision_score\n","import pickle as pkl\n","import os\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","\n","from ST_GCN.feeder import Feeder\n","from ST_GCN.st_gcn import Model as ST_GCN\n","from CTR_GCN.ctrgcn import Model as CTR_GCN\n","\n","from SkateFormer.feeder_skateformer import Feeder as Feeder_skateformer\n","from SkateFormer.SkateFormer import SkateFormer_ as SkateFormer"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1741226369686,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"Xtx1Vo804BnO"},"outputs":[],"source":["def mixup_data(x, y, alpha=0.3):\n","    \"\"\"\n","    Applies Mixup augmentation on skeleton data.\n","\n","    Args:\n","        x: Tensor of shape (batch_size, channels, frames, joints, 1)\n","        y: Tensor of shape (batch_size,)\n","        alpha: Mixup hyperparameter (default=0.2)\n","\n","    Returns:\n","        Mixed input, Mixed target, Lambda value\n","    \"\"\"\n","    if alpha > 0:\n","        lam = np.random.beta(alpha, alpha)  # Sample λ from Beta(α, α)\n","    else:\n","        lam = 1\n","\n","    batch_size = x.size(0)\n","    index = torch.randperm(batch_size).to(x.device)  # Shuffle indices\n","\n","    mixed_x = lam * x + (1 - lam) * x[index, :]  # Mixup on inputs\n","    y_a, y_b = y, y[index]  # Keep original labels\n","\n","    return mixed_x, y_a, y_b, lam\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def mixup_criterion(criterion, pred, y_a, y_b, lam):\n","    \"\"\"\n","    Compute the Mixup loss as a weighted sum of two labels.\n","    \"\"\"\n","    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1741226369689,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"euFDx9BULreE"},"outputs":[],"source":["def compute_effective_number_weights(labels, beta=0.9999):\n","    \"\"\"\n","    Compute class weights based on the effective number of samples.\n","\n","    Args:\n","        labels (array-like): Array or list of class labels.\n","        beta (float): Hyperparameter in [0, 1). Typically very close to 1.\n","\n","    Returns:\n","        dict: Mapping from class label to computed weight.\n","    \"\"\"\n","    classes, counts = np.unique(labels, return_counts=True)\n","    weights = {}\n","    for cls, count in zip(classes, counts):\n","        effective_num = 1.0 - beta ** count\n","        weights[cls] = (1.0 - beta) / effective_num if effective_num != 0 else 0.0\n","    # Optional: normalize weights so that their sum is 1\n","    weight_sum = sum(weights.values())\n","    weights = {cls: float(w / weight_sum) for cls, w in weights.items()}\n","    return weights\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1741226369691,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"nWQZvoErLuL7"},"outputs":[],"source":["class EarlyStopping:\n","    def __init__(self, patience=2, delta=0.005):\n","        \"\"\"\n","        Args:\n","            patience (int): How many epochs to wait after last improvement.\n","            delta (float): Minimum change to qualify as an improvement.\n","            path (str): Path to save the best model.\n","        \"\"\"\n","        self.patience = patience\n","        self.delta = delta\n","        self.best_score = None\n","        self.best_acc = None\n","        self.best_model = None\n","        self.epochs_no_improve = 0\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss, metric, model):\n","        \"\"\"\n","        Check if the validation loss improved, otherwise update patience counter.\n","        \"\"\"\n","        score = -val_loss  # Lower validation loss is better\n","\n","        if self.best_score is None or score > self.best_score + self.delta:\n","            self.best_score = score\n","            self.epochs_no_improve = 0\n","            if self.best_acc is None or  metric > self.best_acc:\n","                self.best_acc = metric\n","                self.best_model = model\n","        else:\n","            self.epochs_no_improve += 1\n","\n","        if self.epochs_no_improve >= self.patience:\n","            self.early_stop = True\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1741226369695,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"LkDIojHdLxKx"},"outputs":[],"source":["# Fix Random seed\n","torch.manual_seed(0)\n","np.random.seed(0)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def plot_confuse_matrix(y_true, y_pred, classes):\n","    \"\"\"\n","    Plot confusion matrix using seaborn.\n","    \"\"\"\n","    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n","    plt.figure(figsize=(5, 4))\n","    sns.heatmap(cm, annot=True, cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n","    plt.xlabel('Predicted label')\n","    plt.ylabel('True label')\n","    plt.title('Confusion Matrix')\n","    plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def show_topk(result, label, k=1):\n","    \"\"\"\n","    Computes top-k accuracy. By default, k=1 => top-1 accuracy.\n","    \"\"\"\n","    topk_idx = result.argsort()\n","    hit_top_k = [l in topk_idx[i, -k:] for i, l in enumerate(label)]\n","    accuracy = sum(hit_top_k) / len(hit_top_k)\n","    return accuracy * 100"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def train(epoch, scheduler, model, optimizer, criterion, data_loader, device, \n","          disease=\"dystonia\", model_type='st_gcn', mixup=True, verbose=True):\n","    model.train()\n","    print(\"Learning Rate:\", scheduler.get_last_lr()[0])\n","\n","    loader = data_loader['train']\n","    loss_value = []\n","\n","    \n","    for batch_idx, batch in enumerate(loader):\n","        if model_type == 'st_gcn' or model_type == 'ctr_gcn':\n","            data, label = batch\n","            data = data.float().to(device)\n","        elif model_type == 'skateformer':\n","            data, label, index_t = batch\n","            data = data.float().to(device)\n","            index_t = index_t.long().to(device)\n","        else:\n","            raise ValueError(\"Invalid model type\")\n","        \n","        # Using 4th column (index=3) as label, adjust if needed\n","        if disease == \"dystonia_duration\":\n","            label = label[:, 3].long().to(device)\n","        elif disease == \"dystonia_amplitude\":\n","            label = label[:, 4].long().to(device)\n","        elif disease == \"choreoathetosis_duration\":\n","            label = label[:, 5].long().to(device)\n","        elif disease == \"choreoathetosis_amplitude\":\n","            label = label[:, 6].long().to(device)\n","        elif disease == \"dystonia\":\n","            label = label[:, 7].long().to(device)\n","        elif disease == \"choreoathetosis\":\n","            label = label[:, 8].long().to(device)\n","        else:\n","            raise ValueError(\"Invalid disease type\")\n","\n","        mixup_probability = np.random.rand()\n","        if mixup_probability < 0.3 and mixup:\n","            mixup1 = True\n","        else:\n","            mixup1 = False\n","\n","        # Mixup\n","        if mixup1:\n","            data, label_a, label_b, lam = mixup_data(data, label)\n","            if model_type == 'st_gcn' or model_type == 'ctr_gcn':\n","                output = model(data)\n","            elif model_type == 'skateformer':\n","                output = model(data, index_t)\n","            else:\n","                raise ValueError(\"Invalid model type\")\n","            \n","            loss = mixup_criterion(criterion, output, label_a, label_b, lam)\n","        else:\n","            if model_type == 'st_gcn' or model_type == 'ctr_gcn':\n","                output = model(data)\n","            elif model_type == 'skateformer':\n","                output = model(data, index_t)\n","            else:\n","                raise ValueError(\"Invalid model type\")\n","            loss = criterion(output, label)\n","\n","        # Backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss_value.append(loss.item())\n","\n","        if (batch_idx + 1) % 10 == 0 and verbose:\n","            print(\"Epoch: {}/{} || Batch: {}/{} || Loss: {:.4f}\".format(\n","                epoch + 1, EPOCH, batch_idx + 1, len(loader), loss.item()))\n","\n","    # End-of-epoch logs\n","    mean_loss = float(np.mean(loss_value))\n","    if verbose:\n","        print(\"Epoch: {}/{} => Mean Loss: {:.4f}\".format(epoch + 1, EPOCH, mean_loss))\n","\n","    return mean_loss"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def test(epoch, model, criterion, data_loader, device, evaluation=True, model_type='st_gcn',\n","         disease=\"dystonia\", verbose=True):\n","    \"\"\"\n","    For validation or test: pass evaluation=True to compute loss & metrics.\n","    Returns (mean_loss, top1, f1, recall, precision, preds, labels) if evaluation=True.\n","    Otherwise, just returns the raw outputs.\n","    \"\"\"\n","    model.eval()\n","    loader = data_loader['val']\n","    loss_value = []\n","    result_frag = []\n","    label_frag = []\n","\n","    with torch.no_grad():\n","        for batch_idx, batch in enumerate(loader):\n","            if model_type == 'st_gcn' or model_type == 'ctr_gcn':\n","                data, label = batch\n","                data = data.float().to(device)\n","            elif model_type == 'skateformer':\n","                data, label, index_t = batch\n","                data = data.float().to(device)\n","                index_t = index_t.long().to(device)\n","            else:\n","                raise ValueError(\"Invalid model type\")\n","            \n","            if disease == \"dystonia_duration\":\n","                label_gpu = label[:, 3].long().to(device)\n","            elif disease == \"dystonia_amplitude\":\n","                label_gpu = label[:, 4].long().to(device)\n","            elif disease == \"choreoathetosis_duration\":\n","                label_gpu = label[:, 5].long().to(device)\n","            elif disease == \"choreoathetosis_amplitude\":\n","                label_gpu = label[:, 6].long().to(device)\n","            elif disease == \"dystonia\":\n","                label_gpu = label[:, 7].long().to(device)\n","            elif disease == \"choreoathetosis\":\n","                label_gpu = label[:, 8].long().to(device)\n","            else:\n","                raise ValueError(\"Invalid disease type\")\n","\n","            if model_type == 'st_gcn' or model_type == 'ctr_gcn':\n","                output = model(data)\n","            elif model_type == 'skateformer':\n","                output = model(data, index_t)\n","            else:\n","                raise ValueError(\"Invalid model type\")\n","            \n","            result_frag.append(output.cpu().numpy())\n","\n","            if evaluation:\n","                loss = criterion(output, label_gpu)\n","                loss_value.append(loss.item())\n","                label_frag.append(label_gpu.cpu().numpy())\n","\n","    result = np.concatenate(result_frag, axis=0)\n","\n","    if evaluation and len(loss_value) > 0:\n","        mean_loss = np.mean(loss_value)\n","        labels = np.concatenate(label_frag, axis=0)\n","        preds = np.argmax(result, axis=1)\n","\n","        top1 = show_topk(result, labels, k=1)\n","        f1 = f1_score(labels, preds, average='macro', zero_division=True)\n","        recall = recall_score(labels, preds, average='macro', zero_division=True)\n","        precision = precision_score(labels, preds, average='macro', zero_division=True)\n","        \n","        if verbose:\n","            print(\"Val Mean Loss: {:.4f}  Top-1: {:.2f}%  F1: {:.2f}%  Recall: {:.2f}%  Precision: {:.2f}%\"\n","                .format(mean_loss, top1, f1 * 100, recall * 100, precision * 100))\n","\n","        return mean_loss, top1, f1, recall, precision, preds, labels\n","    else:\n","        # Either no evaluation or empty loader\n","        return None"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def main(dataset_loader, fold, subject_id, model_type='st_gcn', disease=\"dystonia\", verbose=True):\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Initialize model\n","    if model_type == \"st_gcn\":\n","        model = ST_GCN(\n","            num_class=NUM_CLASS,\n","            in_channels=IN_CHANNEL,\n","            graph_args={'strategy': 'spatial'},\n","            dropout=DROPOUT,\n","            edge_importance_weighting=True\n","        ).to(device)\n","    elif model_type == \"ctr_gcn\":\n","        model = CTR_GCN(\n","            graph_args={'strategy': 'spatial'}, \n","            drop_out=DROPOUT, \n","            in_channels=IN_CHANNEL, \n","            num_class=NUM_CLASS).to(device)\n","    elif model_type == \"skateformer\":\n","        model = SkateFormer(\n","            in_channels=6,\n","            num_frames=100,\n","            num_points=5,\n","            num_classes=NUM_CLASS,\n","        )\n","    else:\n","        raise ValueError(\"Invalid model type\")\n","\n","    # Example weighting if you have imbalance\n","    if disease == \"dystonia_duration\":\n","        ld = dataset_loader['train'].dataset.label[:, 3]\n","    elif disease == \"dystonia_amplitude\":\n","        ld = dataset_loader['train'].dataset.label[:, 4]\n","    elif disease == \"choreoathetosis_duration\":\n","        ld = dataset_loader['train'].dataset.label[:, 5]\n","    elif disease == \"choreoathetosis_amplitude\":\n","        ld = dataset_loader['train'].dataset.label[:, 6]\n","    elif disease == \"dystonia\":\n","        ld = dataset_loader['train'].dataset.label[:, 7]\n","    elif disease == \"choreoathetosis\":\n","        ld = dataset_loader['train'].dataset.label[:, 8]\n","    else:\n","        raise ValueError(\"Invalid disease type\")\n","    alpha_dict = compute_effective_number_weights(ld, beta=0.995)  # If you have a custom function\n","    alpha = list(alpha_dict.values())\n","    class_weight = torch.tensor(alpha).to(device)\n","\n","    criterion = nn.CrossEntropyLoss(weight=class_weight)\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","    scheduler1 = CosineAnnealingLR(optimizer, T_max=EPOCH, eta_min=1e-7)\n","    scheduler2 = StepLR(optimizer, step_size=10, gamma=0.5)\n","\n","    early_stopping = EarlyStopping(patience=5, delta=0.0001)\n","\n","    train_losses, val_losses = [], []\n","    best_model = None\n","    best_metrics = None  # (val_loss, top1, f1, recall, precision)\n","\n","    for epoch in range(EPOCH):\n","        # Train\n","        if verbose:\n","            print(f\"\\n[Subject {subject_id}, Fold {fold}] Epoch {epoch+1}/{EPOCH} - TRAIN\")\n","        train_loss = train(epoch, scheduler1, model, optimizer, criterion, dataset_loader, \n","                           device, mixup=True, verbose=verbose, disease=disease, model_type=model_type)\n","        train_losses.append(train_loss)\n","\n","        # Validate\n","        if verbose:\n","            print(f\"[Subject {subject_id}, Fold {fold}] Epoch {epoch+1}/{EPOCH} - VALIDATION\")\n","        val_out = test(epoch, model, criterion, dataset_loader, device, \n","                       evaluation=True, verbose=verbose, disease=disease, model_type=model_type)\n","        if val_out is not None:\n","            val_loss, top1, f1, recall, precision, preds, labels = val_out\n","            val_losses.append(val_loss)\n","        else:\n","            # If empty val set\n","            val_loss, top1, f1, recall, precision = (np.inf, 0, 0, 0, 0)\n","            val_losses.append(val_loss)\n","\n","        # Step schedulers\n","        scheduler1.step()\n","        scheduler2.step()\n","\n","        # Early stopping check\n","        metric_to_optimize = 0.6 * f1 + 0.4 * top1\n","        early_stopping(val_loss, metric_to_optimize, model)\n","        best_model = early_stopping.best_model\n","\n","        # Save checkpoint every 5 epochs\n","        if (epoch + 1) % 5 == 0 and verbose:\n","            now_str = datetime.now().strftime(\"%d-%m-%Y_%H:%M:%S\")\n","            ckpt_path = f'./Data/6-leave_one_out/subject{subject_id}/fold_{fold}/{disease}/{model_type}/check_points/checkpoint_epoch_{epoch+1}_{now_str}.pth'\n","            torch.save(model.state_dict(), ckpt_path)\n","            print(f\"[INFO] Saved checkpoint => {ckpt_path}\")\n","\n","        if early_stopping.early_stop and verbose:\n","            print(\"[INFO] Early stopping triggered.\")\n","            break\n","\n","    # Save the best model for this fold\n","    best_model_path = f'./Data/6-leave_one_out/subject{subject_id}/fold_{fold}/{disease}/{model_type}/best_model/best_model.pth'\n","    torch.save(best_model.state_dict(), best_model_path)\n","    if verbose:\n","        print(f\"[INFO] Best model stored => {best_model_path}\")\n","\n","    # Plot training curves (optional)\n","    plt.plot(train_losses, label='Train Loss')\n","    plt.plot(val_losses, label='Val Loss')\n","    plt.legend()\n","    plt.title(f\"Subject {subject_id} - Fold {fold} Training\")\n","    plt.show()\n","\n","    return best_model_path  # Return path to best model for later inference"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def inference_on_test(best_model_path, test_data_path, test_labels_path, device, model_type='st_gcn', disease=\"dystonia\"):\n","    \"\"\"\n","    Loads the best model, runs inference on test_data, returns predictions & labels.\n","    \"\"\"\n","    if model_type == \"st_gcn\":\n","        model = ST_GCN(\n","            num_class=NUM_CLASS,\n","            in_channels=IN_CHANNEL,\n","            graph_args={'strategy': 'spatial'},\n","            dropout=DROPOUT,\n","            edge_importance_weighting=True\n","        ).to(device)\n","    elif model_type == \"ctr_gcn\":\n","        model = CTR_GCN(\n","            graph_args={'strategy': 'spatial'}, \n","            drop_out=DROPOUT, \n","            in_channels=IN_CHANNEL, \n","            num_class=NUM_CLASS).to(device)\n","    elif model_type == \"skateformer\":\n","        model = SkateFormer(\n","            num_frames=64\n","        )\n","    else:\n","        raise ValueError(f\"Invalid model type: {model_type}\")\n","\n","    # Load weights\n","    model.load_state_dict(torch.load(best_model_path, map_location=device))\n","    model.eval()\n","\n","    # Prepare test dataset\n","    test_dataset = Feeder(data_path=test_data_path,\n","                                   label_path=test_labels_path,\n","                                   mmap=False, augment=True)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, label) in enumerate(test_loader):\n","            data = data.float().to(device)\n","            if disease == \"dystonia_duration\":\n","                label_gpu = label[:, 3].long().to(device)\n","            elif disease == \"dystonia_amplitude\":\n","                label_gpu = label[:, 4].long().to(device)\n","            elif disease == \"choreoathetosis_duration\":\n","                label_gpu = label[:, 5].long().to(device)\n","            elif disease == \"choreoathetosis_amplitude\":\n","                label_gpu = label[:, 6].long().to(device)\n","            elif disease == \"dystonia\":\n","                label_gpu = label[:, 7].long().to(device)\n","            elif disease == \"choreoathetosis\":\n","                label_gpu = label[:, 8].long().to(device)\n","            else:\n","                raise ValueError(\"Invalid disease type\")\n","\n","            output = model(data)\n","            preds = torch.argmax(output, dim=1)\n","\n","            all_preds.append(preds.cpu().numpy())\n","            all_labels.append(label_gpu.cpu().numpy())\n","\n","    all_preds = np.concatenate(all_preds, axis=0)\n","    all_labels = np.concatenate(all_labels, axis=0)\n","    return all_preds, all_labels"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def run_loso_5_fold_training(type = \"st_gcn\", disease = \"dystonia\", verbose=True):\n","    \"\"\"\n","    For each subjectX in ./Data/LOSO:\n","      1) load subject test_data/test_labels\n","      2) for each fold_0..4:\n","         a) load train_data, val_data\n","         b) train => yields best_model.pth\n","         c) track which fold had the best validation metric\n","      3) after checking all 5 folds, use the best fold's model => test inference\n","      4) accumulate predictions in global lists => confusion matrix at the end\n","    \"\"\"\n","    base_loso_dir = \"./Data/6-leave_one_out\"\n","    subject_dirs = sorted(glob.glob(os.path.join(base_loso_dir, \"subject*\")))\n","\n","    # Collect predictions/labels from all subjects' test data\n","    all_preds_global = []\n","    all_labels_global = []\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    for subj_path in subject_dirs:\n","        subject_id = os.path.basename(subj_path).replace(\"subject\", \"\")\n","        print(f\"\\n====== LOSO for subject {subject_id} ======\")\n","\n","        # 1) Load this subject's test data\n","        test_data_path = os.path.join(subj_path, \"test_data.npy\")\n","        test_label_path = os.path.join(subj_path, \"test_labels.pkl\")\n","\n","        os.makedirs(os.path.join(subj_path, f\"{disease}/{type}/\"), exist_ok=True)\n","\n","        if not (os.path.exists(test_data_path) and os.path.exists(test_label_path)):\n","            print(f\"[WARN] Subject {subject_id} missing test data/labels. Skipping.\")\n","            continue\n","\n","        # 2) For each fold, we do training => track best fold\n","        best_fold = None\n","        best_fold_metric = -999\n","        best_fold_model_path = None\n","        best_fold_model = None\n","\n","        for fold_num in range(5):\n","            fold_dir = os.path.join(subj_path, f\"fold_{fold_num}\")\n","\n","            check_points_dir = os.path.join(fold_dir, f\"{disease}/{type}/check_points\")\n","            best_models_dir = os.path.join(fold_dir, f\"{disease}/{type}/best_model\")\n","\n","            os.makedirs(check_points_dir, exist_ok=True)\n","            os.makedirs(best_models_dir, exist_ok=True)\n","\n","            print(check_points_dir, best_models_dir)\n","\n","            if not os.path.isdir(fold_dir):\n","                print(f\"[WARN] No fold_{fold_num} directory. Skipping.\")\n","                continue\n","\n","            # --- Load train/val data ---\n","            train_data_path = os.path.join(fold_dir, \"train_data.npy\")\n","            train_label_path = os.path.join(fold_dir, \"train_labels.pkl\")\n","            val_data_path = os.path.join(fold_dir, \"val_data.npy\")\n","            val_label_path = os.path.join(fold_dir, \"val_labels.pkl\")\n","\n","            if not all(os.path.exists(p) for p in [train_data_path, train_label_path, val_data_path, val_label_path]):\n","                print(f\"[WARN] Missing train/val for fold_{fold_num}. Skipping.\")\n","                continue\n","\n","            # --- Build DataLoaders ---\n","            if type == \"st_gcn\" or type == \"ctr_gcn\":\n","                train_dataset = Feeder(data_path=train_data_path,\n","                                    label_path=train_label_path,\n","                                    mmap=False, augment=True)\n","                val_dataset   = Feeder(data_path=val_data_path,\n","                                    label_path=val_label_path,\n","                                    mmap=False, augment=True)\n","            elif type == \"skateformer\":\n","                train_dataset = Feeder_skateformer(data_path=train_data_path,\n","                                    label_path=train_label_path,\n","                                    mmap=False, augment=True)\n","                val_dataset   = Feeder_skateformer(data_path=val_data_path,\n","                                    label_path=val_label_path,\n","                                    mmap=False, augment=True)\n","\n","            data_loader = {\n","                'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2),\n","                'val':   DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","            }\n","\n","            # --- Train for this fold => returns path to best model\n","            best_model_path = main(data_loader, fold_num, subject_id, model_type=type, disease=disease, verbose=verbose)\n","\n","            # --- Validate on the best model ---\n","            if type == \"st_gcn\":\n","                model_check = ST_GCN(\n","                    num_class=NUM_CLASS,\n","                    in_channels=IN_CHANNEL,\n","                    graph_args={'strategy': 'spatial'},\n","                    dropout=DROPOUT,\n","                    edge_importance_weighting=True\n","                ).to(device)\n","            elif type == \"ctr_gcn\":\n","                model_check = CTR_GCN(graph_args={'strategy': 'spatial'}, \n","                                      drop_out=DROPOUT, \n","                                      in_channels=IN_CHANNEL, \n","                                      num_class=NUM_CLASS).to(device)\n","            elif type == \"skateformer\":\n","                model_check = SkateFormer(\n","                    in_channels=6,\n","                    num_frames=100,\n","                    num_points=5,\n","                    num_classes=NUM_CLASS,\n","                ).to(device)\n","            else:\n","                print(f\"[WARN] Unknown model type: {type}. Skipping.\")\n","                return\n","\n","            model_check.load_state_dict(torch.load(best_model_path, map_location=device))\n","            model_check.eval()\n","\n","            val_loss, top1, f1_val, r, p, preds_val, labels_val = test(\n","                epoch=EPOCH,\n","                model=model_check,\n","                criterion=nn.CrossEntropyLoss(),\n","                data_loader=data_loader,\n","                device=device,\n","                evaluation=True,\n","                verbose=verbose,\n","                disease=disease\n","            )\n","\n","            # Weighted metric (e.g., 0.6*f1 + 0.4*top1)\n","            fold_metric = 0.6*f1_val + 0.4*top1\n","            print(f\"[Subject {subject_id}] Fold {fold_num} => Weighted metric: {fold_metric:.2f}\")\n","\n","            # Keep track of the best fold\n","            if fold_metric > best_fold_metric:\n","                best_fold_metric = fold_metric\n","                best_fold = fold_num\n","                best_fold_model_path = best_model_path\n","                best_fold_model = model_check\n","\n","        # 3) Inference on test data using the best fold\n","        if best_fold_model_path is None:\n","            print(f\"[WARN] Subject {subject_id} has no valid folds. Skipping test inference.\")\n","            continue\n","        \n","        torch.save(best_fold_model.state_dict(), f\"./Data/6-leave_one_out/subject{subject_id}/{disease}/{type}/best_model.pth\")\n","        print(f\"\\n[Subject {subject_id}] Best fold is {best_fold} with metric {best_fold_metric:.2f}. Inference on test...\")\n","        preds_subj, labels_subj = inference_on_test(best_fold_model_path, test_data_path, test_label_path, device, model_type=type, disease=disease)\n","\n","        # 4) Store them in global lists\n","        all_preds_global.append(preds_subj)\n","        all_labels_global.append(labels_subj)\n","\n","    # 5) Final confusion matrix / classification report across all subjects\n","    if len(all_preds_global) == 0:\n","        print(\"\\nNo predictions collected. Check your data/folder structure.\")\n","        return\n","\n","    all_preds_global = np.concatenate(all_preds_global, axis=0)\n","    all_labels_global = np.concatenate(all_labels_global, axis=0)\n","\n","    print(\"\\n=========== Global LOSO Test Results ===========\")\n","    if disease == \"dystonia\" or disease == \"choreoathetosis\":\n","        classes = [0, 1]\n","    else:\n","        classes = [0, 1, 2, 3, 4]\n","    plot_confuse_matrix(all_labels_global, all_preds_global, classes=classes)\n","    print(\"\\nClassification Report:\\n\", classification_report(all_labels_global, all_preds_global))"]},{"cell_type":"markdown","metadata":{},"source":["# Dystonia Duration"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","====== LOSO for subject 1 ======\n","./Data/6-leave_one_out/subject1/fold_0/dystonia_duration/st_gcn/check_points ./Data/6-leave_one_out/subject1/fold_0/dystonia_duration/st_gcn/best_model\n","\n","[Subject 1, Fold 0] Epoch 1/30 - TRAIN\n","Learning Rate: 0.0005\n","[Subject 1, Fold 0] Epoch 1/30 - VALIDATION\n","\n","[Subject 1, Fold 0] Epoch 2/30 - TRAIN\n","Learning Rate: 0.0004986307477473\n","[Subject 1, Fold 0] Epoch 2/30 - VALIDATION\n","\n","[Subject 1, Fold 0] Epoch 3/30 - TRAIN\n","Learning Rate: 0.0004945379928034148\n","[Subject 1, Fold 0] Epoch 3/30 - VALIDATION\n","\n","[Subject 1, Fold 0] Epoch 4/30 - TRAIN\n","Learning Rate: 0.00048776657624797375\n","[Subject 1, Fold 0] Epoch 4/30 - VALIDATION\n","\n","[Subject 1, Fold 0] Epoch 5/30 - TRAIN\n","Learning Rate: 0.00047839068713776816\n","[Subject 1, Fold 0] Epoch 5/30 - VALIDATION\n","[INFO] Saved checkpoint => ./Data/6-leave_one_out/subject1/fold_0/dystonia_duration/st_gcn/check_points/checkpoint_epoch_5_19-03-2025_04:19:45.pth\n","\n","[Subject 1, Fold 0] Epoch 6/30 - TRAIN\n","Learning Rate: 0.0004665130496759206\n","[Subject 1, Fold 0] Epoch 6/30 - VALIDATION\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"<string>\", line 1, in <module>\n","  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n","    self = reduction.pickle.load(from_parent)\n","_pickle.UnpicklingError: pickle data was truncated\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m NUM_CLASS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      9\u001b[0m IN_CHANNEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mrun_loso_5_fold_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mst_gcn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdystonia_duration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 88\u001b[0m, in \u001b[0;36mrun_loso_5_fold_training\u001b[0;34m(type, disease, verbose)\u001b[0m\n\u001b[1;32m     82\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m:   DataLoader(val_dataset,   batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     85\u001b[0m }\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# --- Train for this fold => returns path to best model\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisease\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# --- Validate on the best model ---\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mst_gcn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","Cell \u001b[0;32mIn[22], line 69\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dataset_loader, fold, subject_id, model_type, disease, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Subject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - VALIDATION\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m val_out \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m               \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisease\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     val_loss, top1, f1, recall, precision, preds, labels \u001b[38;5;241m=\u001b[39m val_out\n","Cell \u001b[0;32mIn[10], line 15\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(epoch, model, criterion, data_loader, device, evaluation, model_type, disease, verbose)\u001b[0m\n\u001b[1;32m     12\u001b[0m label_frag \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mst_gcn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctr_gcn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     17\u001b[0m             data, label \u001b[38;5;241m=\u001b[39m batch\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 5e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"st_gcn\", disease=\"dystonia_duration\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","====== LOSO for subject 1 ======\n","./Data/6-leave_one_out/subject1/fold_0/dystonia_duration/ctr_gcn/check_points ./Data/6-leave_one_out/subject1/fold_0/dystonia_duration/ctr_gcn/best_model\n","\n","[Subject 1, Fold 0] Epoch 1/30 - TRAIN\n","Learning Rate: 0.0005\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m NUM_CLASS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      9\u001b[0m IN_CHANNEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mrun_loso_5_fold_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mctr_gcn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdystonia_duration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[15], line 88\u001b[0m, in \u001b[0;36mrun_loso_5_fold_training\u001b[0;34m(type, disease, verbose)\u001b[0m\n\u001b[1;32m     82\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m:   DataLoader(val_dataset,   batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     85\u001b[0m }\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# --- Train for this fold => returns path to best model\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisease\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# --- Validate on the best model ---\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mst_gcn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","Cell \u001b[0;32mIn[11], line 60\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dataset_loader, fold, subject_id, model_type, disease, verbose)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCH):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[Subject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - TRAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisease\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n","Cell \u001b[0;32mIn[9], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, scheduler, model, optimizer, criterion, data_loader, device, disease, model_type, mixup, verbose)\u001b[0m\n\u001b[1;32m      6\u001b[0m loader \u001b[38;5;241m=\u001b[39m data_loader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mst_gcn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctr_gcn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     12\u001b[0m         data, label \u001b[38;5;241m=\u001b[39m batch\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 5e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"ctr_gcn\", disease=\"dystonia_duration\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","====== LOSO for subject 1 ======\n","./Data/6-leave_one_out/subject1/fold_0/dystonia_amplitude/skateformer/check_points ./Data/6-leave_one_out/subject1/fold_0/dystonia_amplitude/skateformer/best_model\n"]},{"ename":"TypeError","evalue":"SkateFormer.SkateFormer.SkateFormer() got multiple values for keyword argument 'depths'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m NUM_CLASS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      9\u001b[0m IN_CHANNEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mrun_loso_5_fold_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mskateformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdystonia_amplitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 88\u001b[0m, in \u001b[0;36mrun_loso_5_fold_training\u001b[0;34m(type, disease, verbose)\u001b[0m\n\u001b[1;32m     82\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m:   DataLoader(val_dataset,   batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     85\u001b[0m }\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# --- Train for this fold => returns path to best model\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisease\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# --- Validate on the best model ---\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mst_gcn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","Cell \u001b[0;32mIn[18], line 21\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dataset_loader, fold, subject_id, model_type, disease, verbose)\u001b[0m\n\u001b[1;32m     15\u001b[0m     model \u001b[38;5;241m=\u001b[39m CTR_GCN(\n\u001b[1;32m     16\u001b[0m         graph_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m'\u001b[39m}, \n\u001b[1;32m     17\u001b[0m         drop_out\u001b[38;5;241m=\u001b[39mDROPOUT, \n\u001b[1;32m     18\u001b[0m         in_channels\u001b[38;5;241m=\u001b[39mIN_CHANNEL, \n\u001b[1;32m     19\u001b[0m         num_class\u001b[38;5;241m=\u001b[39mNUM_CLASS)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskateformer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 21\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSkateFormer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdepths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CLASS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid model type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/Desktop/MY_ST_GCN 4/SkateFormer/SkateFormer.py:511\u001b[0m, in \u001b[0;36mSkateFormer_\u001b[0;34m(dropout, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSkateFormer_\u001b[39m(dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkateFormer(\n\u001b[1;32m    512\u001b[0m         depths\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m    513\u001b[0m         channels\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m192\u001b[39m, \u001b[38;5;241m192\u001b[39m, \u001b[38;5;241m192\u001b[39m),\n\u001b[1;32m    514\u001b[0m         embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m96\u001b[39m,\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    516\u001b[0m     )\n","\u001b[0;31mTypeError\u001b[0m: SkateFormer.SkateFormer.SkateFormer() got multiple values for keyword argument 'depths'"]}],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 5e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"skateformer\", disease=\"dystonia_amplitude\", verbose=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Dystonia Amplitude"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 5e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"st_gcn\", disease=\"dystonia_amplitude\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 5e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"ctr_gcn\", disease=\"dystonia_amplitude\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 5e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"skateformer\", disease=\"dystonia_amplitude\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Choreoaethetosis Duration"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 1e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"st_gcn\", disease=\"choreoathetosis_duration\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 1e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"ctr_gcn\", disease=\"choreoathetosis_duration\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 1e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"skateformer\", disease=\"choreoathetosis_duration\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Choreoaethetosis Amplitude"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 1e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"st_gcn\", disease=\"choreoathetosis_amplitude\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 1e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"ctr_gcn\", disease=\"choreoathetosis_amplitude\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 1e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 5\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"skateformer\", disease=\"choreoathetosis_amplitude\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Dystonia"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1evi9ATr9MuIOA2bLXmj7gDN-BSKVQgYq"},"executionInfo":{"elapsed":2293992,"status":"ok","timestamp":1741223957708,"user":{"displayName":"Fuyan Zhang","userId":"08187330620497980103"},"user_tz":0},"id":"av8-xObugENz","outputId":"968633ea-fdaf-4768-c8cc-16cc798189d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","No predictions collected. Check your data/folder structure.\n"]}],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 5e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 2\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"st_gcn\", disease=\"dystonia\", verbose=False)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 5e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 2\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"ctr_gcn\", disease=\"dystonia\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 5e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 2\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"skateformer\", disease=\"dystonia\", verbose=False)"]},{"cell_type":"markdown","metadata":{"id":"h8g5pRccc9Mt"},"source":["# Choreoathetosis"]},{"cell_type":"markdown","metadata":{},"source":["## ST-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 1e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 2\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"st_gcn\", disease=\"choreoathetosis\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## CTR-GCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 1e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 2\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"ctr_gcn\", disease=\"choreoathetosis\", verbose=False)"]},{"cell_type":"markdown","metadata":{},"source":["## SkateFormer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == '__main__':\n","    LEARNING_RATE = 1e-4\n","    EPOCH = 30\n","    BATCH_SIZE = 32\n","    WEIGHT_DECAY = 1e-4\n","    DROPOUT = 0.5\n","\n","    NUM_CLASS = 2\n","    IN_CHANNEL = 6\n","    run_loso_5_fold_training(type=\"skateformer\", disease=\"choreoathetosis\", verbose=False)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNdUzK3foejmPZWxfA8b0zY","gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
